#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""pr
Created on Sat Nov 16 18:44:33 2019

@author: divyarth
"""
import nltk
from nltk.corpus import stopwords
import numpy as np
import pandas as pd
from nltk.stem import PorterStemmer
import sys

ps = PorterStemmer()
stop_words=np.array(['yourself', 'beprintlow', "shouldnt", 'again', 'doing', 'their',
       'this', 'o', 'neednt', 'doesnt', 'its', 'in', 'but', 'had', "youtre",
       "dont", 'hers', 'once', 'there', 'mightnt', 'yourselves', 'your',
       'off', 'only', 'dont', 'as', 'or', 'shant', "shes", "shouldve",
       'ours', "its", 'where', 'ma', 'wasn', 'then', 'further', 'such',
       'just', 'under', 'and', 'other', "wont", 'who', "couldnt",
       "wasnt", 'both', 'than', 'here', 'any', 've', 'been', 'theirs',
       'll', 'to', "arent", 'above', "hadnt", 'more', 'an', "youll",
       'each', 'not', 'about', 'should', 'itself', 'down', 'can', 'when',
       'being', 'with', 'so', 'm', 'mustn', "werent", 'my', 'these',
       'me', 'most', 'hadnt', "hasnt", 'by', 'between', 'because',
       "youve", 'before', 'few', 's', 'into', 'too', 'do', 'a', 'i',
       'you', 'no', 'was', 'up', 'from', 'has', 'all', "isnt", 'werent',
       'herself', 'very', 'couldnt', 'havent', "doesnt", 'until', 'd',
       'it', 'at', 'y', "mightnt", "wouldnt", 'she', 'how', 'myself',
       'her', 'isnt', 'that', 'through', 'during', 'won', "neednt",
       'after', 'aint', 'arent', 'ourselves', 'for', 'him', 'now', 'didnt',
       "youd", 'whom', 'am', 'have', 'same', 'his', 'our', 'they', 'nor',
       "thatll", 're', 'which', 'the', 'why', "mustnt", 'while', 'if',
       'are', 'did', 'of', 'them', 'themselves', 'hasnt', 'is', 'himself',
       'over', 'be', 'out', 'wouldn', 'what', 'we', 'does', 'against',
       'shouldn', "havent", 'those', "shant", 'he', 'own', 'having',
       't', "didnt", 'some', 'on', 'will', 'yours', 'were'], dtype='<U10')


#Preprocess Data ~30seconds to run
#sys.argv=['','traindata.csv','testdata.csv','out.txt']

stop_words=np.array(list(stop_words))
lst2=stop_words
                
def parse_txt(txt):
    punc_list='!"#$%&\'()*+,-./:;<=>?@[\\]^_`{|}~'
    a_txt=txt.lower()
    for punc in punc_list:
        a_txt = a_txt.replace(punc, '')
    lst=np.unique(np.array(a_txt.split(' ')))
    out=[]
    for w in lst: 
        if w not in stop_words: 
            out.append(ps.stem(w)) 
    return np.unique(np.array(out))

data = pd.read_csv(sys.argv[1],delimiter=',')

y_train=data.iloc[:,1]
bool_ind=y_train=='positive'
y_train[bool_ind]=1
y_train[~bool_ind]=0
y=y_train

X=data.iloc[:,0]
X= X.apply(parse_txt)


data=None
vocab=X.apply(pd.Series).stack().unique()
#vocab=vocab[vocab!='']
n=len(vocab)

def gen_dict():
    dct={}
    i=0
    for a in vocab:
        dct[a]=i
        i+=1
    return dct

alpha=gen_dict()

lst=np.zeros((len(X),len(vocab)),dtype=bool)

for i in range(len(X)):
    
    for a in X[i]:
        lst[i,alpha[a]]=True        

X_train=lst
y_train=y
#X_test=lst1


#Final Preprocessed data

class naive_bayes:
    
    def __init__(self):
        self.X=None
        self.y=None
        self.Xt=None
        self.p_y1=None
        self.p_y2=None    
        self.m=None
        self.cond_px_y1,self.cond_px_y0 =None,None
    
    def prob_x_y(self):
        k=len(self.y)
        p_y1=self.y.sum()+2
        p_y0=(len(self.y)-self.y.sum())+2
        
        self.cond_px_y1=[]
        self.cond_px_y0=[]       
        
#        self.cond_px_y1=self.X.T.dot(self.y.values.reshape(-1,1)).T
        self.m=len(self.X[0])
        for j in range(self.m):
            self.cond_px_y1.append((self.X[:,j][self.y==1].sum()+1)/p_y1)
            self.cond_px_y0.append((self.X[:,j][self.y==0].sum()+1)/p_y0)
        return np.array(self.cond_px_y1),np.array(self.cond_px_y0)
    
    def predict(self,c1,c2):
        self.cond_px_y1,self.cond_px_y0 = c1,c2
        pred=[]
        p_y1=self.y.sum()/len(self.y)
        p_y2=(len(self.y)-self.y.sum())/len(self.y)
        for i in range(len(self.Xt)):  
#           print(self.cond_px_y0[self.Xt[i]==1])
            t1=np.sum(np.log(self.cond_px_y1[self.Xt[i]==1]))
            t2=np.sum(np.log(self.cond_px_y0[self.Xt[i]==1]))
            p1=(t1+np.log(p_y1))
            p2=(t2+np.log(p_y2))
            if p1>p2:
               pred.append(1)
            else :
                pred.append(0)
        return pred
        
nb=naive_bayes()
nb.X=X_train
nb.y=y_train
c1,c2=nb.prob_x_y()

X=pd.read_csv(sys.argv[2],delimiter=',')
X=X.iloc[:,0]
X=X.apply(parse_txt)
pred=[]
for i in range(len(X)):
    
    lst=np.zeros(len(vocab),dtype=bool)
    for a in X[i]:
        try:
            lst[alpha[a]]=True
        except:
            ()
    nb.Xt=[lst*1]
    pred.append(nb.predict(c1,c2))
        
        

#pred=nb.predict(c1,c2)
y_test=np.array(pred).flatten()
np.savetxt(sys.argv[3],y_test,delimiter='\n')
