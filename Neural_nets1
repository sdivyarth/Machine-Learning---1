import numpy as np
import sys

f=open(sys.argv[2],'r')
#f=open('param.txt','r')
s=f.read()

a=s.split()
mode=int(a[0])
eta=float(a[1])
iter0=int(a[2])
batch_size=int(a[3])
neurons= list(map(int,a[4:]))
data = np.loadtxt(sys.argv[1],dtype='float',delimiter=',')
#data = np.loadtxt('train.csv',dtype='float',delimiter=',')

X_train=data[:,:-1]
y_train=data[:,-1].reshape((-1,1))

def get_random_weights(lst):
    n=len(lst)
    w=[]
    b=[]
    for i in range(n-1):
        w.append(np.zeros((lst[i+1],lst[i])))
        b.append(np.zeros((lst[i+1])))
    return np.asarray(w),np.asarray(b)

def sigmoid(z):
    return 1./(1.+np.exp(-z))

def FeedForward(W,b,X):
    
    out=[X]
    for i in range(len(W)):
        Z=out[i].dot(W[i].T)+b[i]
        act=sigmoid(Z)
        out.append(act)
    return out

def Back(W,b,X,y):
    
    A=FeedForward(W,b,X)
    delta= A[-1]-y
    del_=[]
    del_.append(delta)
    
    for i in range(len(W)-1,0,-1):
        delta=delta.dot(W[i])*(A[i]*(1-A[i]))
        del_.append(delta)

    del_.reverse()
    out=[]
    out1=[]
    i=0
    
    for i in range(len(W)):
        alpha=A[i].T.dot(del_[i])/len(X)
        out.append(alpha.T)
        out1.append((del_[i].sum(axis=0))/len(X))

    return np.asarray(out),np.asarray(out1)
    
def gradDes(X,y,w0,b0,eta,iter0,batch_size):
    n=len(X)
    k=int(len(X)/batch_size)
    w=w0
    b=b0
    alpha=0
    
    for i in range(iter0):
        ind=(i%k)*batch_size
        ind1=((i%k)+1)*batch_size
        w0=w
        b0=b
        derW,derb=Back(w0,b0,X[ind:ind1],y[ind:ind1])
        w=w0-eta*(derW)
        b=b0-eta*derb
    return w,b

def gradDesAdap(X,y,w0,b0,eta0,iter0,batch_size):
    n=len(X)
    k=int(len(X)/batch_size)
    w=w0
    b=b0
    for i in range(iter0):
        ind=(i%k)*batch_size
        ind1=((i%k)+1)*batch_size
        w0=w
        b0=b
        derW,derb=Back(w0,b0,X[ind:ind1],y[ind:ind1])
        eta=eta0/(np.sqrt(i+1))
        w=w0-eta*derW
        b=b0-eta*derb
    return w,b


                        
lst=[2]
[lst.append(s) for s in neurons] 
lst.append(1)

w0,b0=get_random_weights(lst)

if mode==1:
    W,b=gradDes(X_train,y_train,w0,b0,eta,int(iter0),batch_size)
else:
    W,b=gradDesAdap(X_train,y_train,w0,b0,eta,int(iter0),batch_size)

weights = open(sys.argv[3], "a")

for i in range(len(W)):
    np.savetxt(weights,b[i],delimiter="\n")
    np.savetxt(weights,W[i].T,delimiter="\n")
